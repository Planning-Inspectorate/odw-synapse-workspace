{
	"name": "Notebook 3",
	"properties": {
		"folder": {
			"name": "Horizon-Migration"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "hbtPool",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "e5632158-17fe-43c3-8b3f-d122064cd5c8"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/hbtPool",
				"name": "hbtPool",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/hbtPool",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.5",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"# INPUT: LLAttrData (EAV) CSV\n",
					"llattrdata_path = \"abfss://horizon-migration-poc@pinsstodwdevuks9h80mb.dfs.core.windows.net/MPESC-EXTRACT/LLAttrData.csv\"\n",
					"\n",
					"# OUTPUT BASE folder\n",
					"output_base = \"abfss://horizon-migration-poc@pinsstodwdevuks9h80mb.dfs.core.windows.net/MPESC-EXTRACT/LLAttr\"\n",
					"\n",
					"print(\"Input :\", llattrdata_path)\n",
					"print(\"Output:\", output_base)\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"df = (\n",
					"    spark.read\n",
					"         .option(\"header\", True)\n",
					"         .csv(llattrdata_path)\n",
					")\n",
					"\n",
					"df.printSchema()\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import functions as F\n",
					"\n",
					"dfv = (\n",
					"    df\n",
					"    .withColumn(\"DefID\", F.col(\"DefID\").cast(\"int\"))\n",
					"    .withColumn(\"ID\", F.col(\"ID\").cast(\"long\"))\n",
					"    .withColumn(\"AttrID\", F.col(\"AttrID\").cast(\"int\"))\n",
					"    .withColumn(\"VerNum\", F.col(\"VerNum\").cast(\"int\"))\n",
					"    .withColumn(\n",
					"        \"Value\",\n",
					"        F.coalesce(\n",
					"            F.col(\"ValStr\"),\n",
					"            F.col(\"ValLong\"),\n",
					"            F.col(\"ValInt\").cast(\"string\"),\n",
					"            F.col(\"ValReal\").cast(\"string\"),\n",
					"            F.date_format(F.col(\"ValDate\"), \"yyyy-MM-dd HH:mm:ss\")\n",
					"        )\n",
					"    )\n",
					"    .select(\"DefID\", \"ID\", \"AttrID\", \"VerNum\", \"Value\")\n",
					")\n",
					"\n",
					"dfv.show(5, truncate=False)\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"dfv_good = (\n",
					"    dfv\n",
					"    .filter(F.col(\"DefID\").isNotNull())\n",
					"    .filter(F.col(\"ID\").isNotNull())\n",
					"    .filter(F.col(\"AttrID\").isNotNull())\n",
					"    .filter(F.col(\"Value\").isNotNull())\n",
					")\n",
					"\n",
					"print(\"Rows kept:\", dfv_good.count())\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"defids = [\n",
					"    r[\"DefID\"] for r in (\n",
					"        dfv_good\n",
					"        .select(\"DefID\")\n",
					"        .distinct()\n",
					"        .collect()\n",
					"    )\n",
					"]\n",
					"\n",
					"print(\"DefIDs found:\", len(defids))\n",
					"print(\"First 20:\", sorted(defids)[:20])\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"# DefID -> friendly file/table name\n",
					"DEFID_TO_TABLE = {\n",
					"\n",
					"    # ======================\n",
					"    # NSIP\n",
					"    # ======================\n",
					"    12361638: \"NSIP_Case\",\n",
					"    12361642: \"NSIP_Applicant\",\n",
					"    12361641: \"NSIP_Key_Dates\",\n",
					"    12361640: \"NSIP_Fees\",\n",
					"    12361645: \"NSIP_Advice\",\n",
					"    12361644: \"NSIP_Document\",\n",
					"\n",
					"    # ======================\n",
					"    # DNS\n",
					"    # ======================\n",
					"    28937821: \"DNS_Case\",\n",
					"    28937822: \"DNS_Dates\",\n",
					"\n",
					"    # ======================\n",
					"    # Core Case\n",
					"    # ======================\n",
					"    95498: \"Case\",\n",
					"    95499: \"Case_Dates\",\n",
					"    15810101: \"Case_Dates_Environment\",\n",
					"    95500: \"Case_Document_Dates\",\n",
					"    95501: \"Case_Involvement\",\n",
					"    95502: \"Case_Site\",\n",
					"    24636544: \"Case_Specific_Object\",\n",
					"\n",
					"    # ======================\n",
					"    # Fees / Finance\n",
					"    # ======================\n",
					"    95504: \"DPA_Fee\",\n",
					"    95505: \"DPA_Fee_Refund\",\n",
					"    95493: \"Abeyance\",\n",
					"\n",
					"    # ======================\n",
					"    # Applications\n",
					"    # ======================\n",
					"    95494: \"Advert_Application\",\n",
					"    95495: \"Advertisement\",\n",
					"    95496: \"Appeal_Ground\",\n",
					"    95497: \"CAS_Type\",\n",
					"    95509: \"Planning_Application\",\n",
					"    95510: \"Planning_Obligation_Application\",\n",
					"    15809661: \"Purchase_Notice\",\n",
					"\n",
					"    # ======================\n",
					"    # Documents / Events\n",
					"    # ======================\n",
					"    95503: \"Document\",\n",
					"    95506: \"Event\",\n",
					"    95507: \"Despatch_Alert\",\n",
					"    95508: \"Notice\",\n",
					"    15169115: \"COSMO_Document\",\n",
					"    17224065: \"Horizon_Publication\",\n",
					"    95511: \"Scanned_Batch\",\n",
					"    95512: \"Template_Task_List\",\n",
					"\n",
					"    # ======================\n",
					"    # Judicial Review / Legal\n",
					"    # ======================\n",
					"    12361643: \"JR_Dates\",\n",
					"    19674254: \"Secretary_Of_State_Decision\",\n",
					"    15809004: \"High_Court_Specialist_Casework\",\n",
					"\n",
					"    # ======================\n",
					"    # Community / Levy\n",
					"    # ======================\n",
					"    21889077: \"Community_Infrastructure_Levy\",\n",
					"    15809441: \"Recharge\",\n",
					"\n",
					"    # ======================\n",
					"    # Coastal / Environmental\n",
					"    # ======================\n",
					"    15809442: \"Coastal_Access\",\n",
					"\n",
					"    # ======================\n",
					"    # Knowledge / Content\n",
					"    # ======================\n",
					"    18122884: \"Knowledge_Document\",\n",
					"\n",
					"    # ======================\n",
					"    # Modification / Orders\n",
					"    # ======================\n",
					"    15809003: \"Modification\",\n",
					"\n",
					"    # ======================\n",
					"    # s62A (Section 62A)\n",
					"    # ======================\n",
					"    12351021: \"s62A_Application_Basic_Data\",\n",
					"    12351020: \"s62A_Key_Dates\",\n",
					"    12351022: \"s62A_Extended_Data\",\n",
					"    12351018: \"s62A_Fees\",\n",
					"    12351019: \"s62A_Hearing\",\n",
					"    12351017: \"s62A_DCLG_Return\",\n",
					"    12351014: \"s62A_Application_Document_Data\",\n",
					"    12351015: \"s62A_Case_Officers\",\n",
					"    12351016: \"s62A_Comment\",\n",
					"    12351023: \"s62A_Publish_Documents\",\n",
					"    12351024: \"s62A_Statutory_Consultees\",\n",
					"\n",
					"    # ======================\n",
					"    # DCLG (Call-in / Orders / Directions etc.)\n",
					"    # ======================\n",
					"    24636659: \"DCLG\",\n",
					"    24636660: \"DCLG_Allotment_Disposal\",\n",
					"    24636661: \"DCLG_Article_4_Direction\",\n",
					"    24636662: \"DCLG_Business_Commercial_NSIP\",\n",
					"    24636663: \"DCLG_Conservation_Area_Demolition\",\n",
					"    24636664: \"DCLG_Consultation_Direction\",\n",
					"    24636665: \"DCLG_Correspondence\",\n",
					"    24636666: \"DCLG_CPO\",\n",
					"    24636667: \"DCLG_EIA\",\n",
					"    24636668: \"DCLG_Green_Belt_Act_1938\",\n",
					"    24636669: \"DCLG_Ground_10A\",\n",
					"    24636670: \"DCLG_Habitats_Regulations\",\n",
					"    24636671: \"DCLG_High_Court\",\n",
					"    24636672: \"DCLG_Lee_Valley\",\n",
					"    24636673: \"DCLG_Less_Than_Best\",\n",
					"    24636674: \"DCLG_Listed_Building_Consent_Private\",\n",
					"    24636675: \"DCLG_Order\",\n",
					"    24636676: \"DCLG_Rare\",\n",
					"    24636677: \"DCLG_Recovered_Case\",\n",
					"    24636678: \"DCLG_Recovered_NSIP\",\n",
					"    24636679: \"DCLG_Request_To_Intervene\",\n",
					"    24636680: \"DCLG_Right_To_Contest\",\n",
					"    24636681: \"DCLG_S100_104\",\n",
					"    24636682: \"DCLG_Section_19_Land_Acquisition\",\n",
					"    24636683: \"DCLG_Document\",\n",
					"}\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.window import Window\n",
					"\n",
					"def extract_one_defid(defid: int):\n",
					"    # Filter to one DefID\n",
					"    d = dfv_good.filter(F.col(\"DefID\") == F.lit(defid))\n",
					"\n",
					"    # Keep latest VerNum per (ID, AttrID)\n",
					"    w = Window.partitionBy(\"ID\", \"AttrID\").orderBy(F.col(\"VerNum\").desc())\n",
					"    d_latest = (\n",
					"        d.withColumn(\"rn\", F.row_number().over(w))\n",
					"         .filter(F.col(\"rn\") == 1)\n",
					"         .drop(\"rn\", \"VerNum\", \"DefID\")\n",
					"    )\n",
					"\n",
					"    # Pivot to wide table (1 row per ID)\n",
					"    wide = (\n",
					"        d_latest\n",
					"        .groupBy(\"ID\")\n",
					"        .pivot(\"AttrID\")\n",
					"        .agg(F.first(\"Value\"))\n",
					"    )\n",
					"\n",
					"    # Write out\n",
					"    table = DEFID_TO_TABLE.get(defid, f\"DefID_{defid}\")\n",
					"    out_dir = f\"{output_base}/{table}_{defid}\"\n",
					"    wide.write.mode(\"overwrite\").option(\"header\", True).csv(out_dir)\n",
					"\n",
					"    print(f\"Wrote DefID {defid} -> {out_dir}\")\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"extract_one_defid(95498)   # Case\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"for d in sorted(defids):\n",
					"    extract_one_defid(d)\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"test_out = f\"{output_base}/DefID=95498\"\n",
					"df_check = spark.read.option(\"header\", True).csv(test_out)\n",
					"print(\"Rows:\", df_check.count())\n",
					"df_check.show(5, truncate=False)\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					""
				],
				"execution_count": null
			}
		]
	}
}