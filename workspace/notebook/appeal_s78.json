{
	"name": "appeal_s78",
	"properties": {
		"folder": {
			"name": "odw-curated"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw34",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "7029501d-4c8c-4546-a6ed-0d67cf5ce0ad"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw34",
				"name": "pinssynspodw34",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw34",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### The purpose of this pyspark notebook is to ingest from odw_harmonised_db.sb_appeal_s78  into a single external table, odw_curated_db.appeal_s78.\r\n",
					"\r\n",
					"**Description**  \r\n",
					"The functionality of this notebook is to ingest data from odw_harmonised_db.sb_appeal_s78 delta table into a single odw_curated_db.appeal_s78 external table.The addtitional functionality has been added to log the audit information to Application Insight by creating a Json dump at notebook exit.\r\n",
					"\r\n",
					"**Spark Cluster Configuration** -> Apache Spark Version- 3.4, Python Version \t\t- 3.10, Delta Lake Version \t- 2.4"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Import Packages"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql.functions import *\r\n",
					"from pyspark.sql.types import *\r\n",
					"from pyspark.sql import DataFrame\r\n",
					"import json"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Initialise Application Insight Logging functions"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"%run utils/py_applicationinsights"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"db_name: str = \"odw_curated_db\"\r\n",
					"entity_name: str = \"appeal-s78\"\r\n",
					"table_name: str = \"odw_curated_db.appeal_s78\"\r\n",
					"\r\n",
					"start_exec_time = datetime.now()\r\n",
					"insert_count = 0\r\n",
					"update_count = 0\r\n",
					"delete_count = 0\r\n",
					"error_message=''"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### <u>**Note:**</u>\r\n",
					"##### In this notebook we use sb_appeal_s78 only as in this phase we are only processing service bus for this entity. \r\n",
					"##### Curated layer will need to be adjusted once we process horizon data."
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**Make sure these are the correct columns that need to be in curated layer. This notebook was run before the schema was fully finalised (some changes from the client were needed to be merged)**"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Create a view for the data, joining harmonised tables where necessary"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"try:\r\n",
					"    df = spark.sql(\"\"\"\r\n",
					"        SELECT\r\n",
					"            caseReference\r\n",
					"            ,caseId\r\n",
					"            ,submissionId\r\n",
					"            ,caseStatus\r\n",
					"            ,caseType\r\n",
					"            ,caseProcedure\r\n",
					"            ,lpaCode\r\n",
					"            ,caseOfficerId\r\n",
					"            ,inspectorId\r\n",
					"            ,allocationLevel\r\n",
					"            ,allocationBand\r\n",
					"            ,caseSpecialisms\r\n",
					"            ,caseSubmittedDate\r\n",
					"            ,caseCreatedDate\r\n",
					"            ,caseUpdatedDate\r\n",
					"            ,caseValidDate\r\n",
					"            ,caseValidationDate\r\n",
					"            ,caseValidationOutcome\r\n",
					"            ,caseValidationInvalidDetails\r\n",
					"            ,caseValidationIncompleteDetails\r\n",
					"            ,caseExtensionDate\r\n",
					"            ,caseStartedDate\r\n",
					"            ,casePublishedDate\r\n",
					"            ,linkedCaseStatus\r\n",
					"            ,leadCaseReference\r\n",
					"            ,lpaQuestionnaireDueDate\r\n",
					"            ,lpaQuestionnaireSubmittedDate\r\n",
					"            ,lpaQuestionnaireCreatedDate\r\n",
					"            ,lpaQuestionnairePublishedDate\r\n",
					"            ,lpaQuestionnaireValidationOutcome\r\n",
					"            ,lpaQuestionnaireValidationOutcomeDate\r\n",
					"            ,lpaQuestionnaireValidationDetails\r\n",
					"            ,lpaStatement\r\n",
					"            ,caseWithdrawnDate\r\n",
					"            ,caseTransferredDate\r\n",
					"            ,transferredCaseClosedDate\r\n",
					"            ,caseDecisionOutcomeDate\r\n",
					"            ,caseDecisionPublishedDate\r\n",
					"            ,caseDecisionOutcome\r\n",
					"            ,caseCompletedDate\r\n",
					"            ,enforcementNotice\r\n",
					"            ,applicationReference\r\n",
					"            ,applicationDate\r\n",
					"            ,applicationDecision\r\n",
					"            ,applicationDecisionDate\r\n",
					"            ,caseSubmissionDueDate\r\n",
					"            ,siteAddressLine1\r\n",
					"            ,siteAddressLine2\r\n",
					"            ,siteAddressTown\r\n",
					"            ,siteAddressCounty\r\n",
					"            ,siteAddressPostcode\r\n",
					"            ,siteAccessDetails\r\n",
					"            ,siteSafetyDetails\r\n",
					"            ,siteAreaSquareMetres\r\n",
					"            ,floorSpaceSquareMetres\r\n",
					"            ,isCorrectAppealType\r\n",
					"            ,isGreenBelt\r\n",
					"            ,inConservationArea\r\n",
					"            ,ownsAllLand\r\n",
					"            ,ownsSomeLand\r\n",
					"            ,knowsOtherOwners\r\n",
					"            ,knowsAllOwners\r\n",
					"            ,advertisedAppeal\r\n",
					"            ,notificationMethod\r\n",
					"            ,ownersInformed\r\n",
					"            ,originalDevelopmentDescription\r\n",
					"            ,changedDevelopmentDescription\r\n",
					"            ,newConditionDetails\r\n",
					"            ,nearbyCaseReferences\r\n",
					"            ,neighbouringSiteAddresses\r\n",
					"            ,affectedListedBuildingNumbers\r\n",
					"            ,changedListedBuildingNumbers\r\n",
					"            ,appellantCostsAppliedFor\r\n",
					"            ,lpaCostsAppliedFor\r\n",
					"            ,agriculturalHolding\r\n",
					"            ,tenantAgriculturalHolding\r\n",
					"            ,otherTenantsAgriculturalHolding\r\n",
					"            ,informedTenantsAgriculturalHolding\r\n",
					"            ,appellantProcedurePreference\r\n",
					"            ,appellantProcedurePreferenceDetails\r\n",
					"            ,appellantProcedurePreferenceDuration\r\n",
					"            ,appellantProcedurePreferenceWitnessCount\r\n",
					"            ,statusPlanningObligation\r\n",
					"            ,affectsScheduledMonument\r\n",
					"            ,hasProtectedSpecies\r\n",
					"            ,isAonbNationalLandscape\r\n",
					"            ,designatedSitesNames\r\n",
					"            ,isGypsyOrTravellerSite\r\n",
					"            ,isPublicRightOfWay\r\n",
					"            ,eiaEnvironmentalImpactSchedule\r\n",
					"            ,eiaDevelopmentDescription\r\n",
					"            ,eiaSensitiveAreaDetails\r\n",
					"            ,eiaColumnTwoThreshold\r\n",
					"            ,eiaScreeningOpinion\r\n",
					"            ,eiaRequiresEnvironmentalStatement\r\n",
					"            ,eiaCompletedEnvironmentalStatement\r\n",
					"            ,consultedBodiesDetails\r\n",
					"            ,hasStatutoryConsultees\r\n",
					"            ,hasInfrastructureLevy\r\n",
					"            ,isInfrastructureLevyFormallyAdopted\r\n",
					"            ,infrastructureLevyAdoptedDate\r\n",
					"            ,infrastructureLevyExpectedDate\r\n",
					"            ,lpaProcedurePreference\r\n",
					"            ,lpaProcedurePreferenceDetails\r\n",
					"            ,lpaProcedurePreferenceDuration\r\n",
					"            ,caseworkReason\r\n",
					"            ,developmentType\r\n",
					"            ,importantInformation\r\n",
					"            ,jurisdiction\r\n",
					"            ,redeterminedIndicator\r\n",
					"            ,dateCostsReportDespatched\r\n",
					"            ,dateNotRecoveredOrDerecovered\r\n",
					"            ,dateRecovered\r\n",
					"            ,originalCaseDecisionDate\r\n",
					"            ,targetDate\r\n",
					"            ,appellantCommentsSubmittedDate\r\n",
					"            ,appellantStatementSubmittedDate\r\n",
					"            ,appellantProofsSubmittedDate\r\n",
					"            ,finalCommentsDueDate\r\n",
					"            ,interestedPartyRepsDueDate\r\n",
					"            ,lpaCommentsSubmittedDate\r\n",
					"            ,lpaProofsSubmittedDate\r\n",
					"            ,lpaStatementSubmittedDate\r\n",
					"            ,proofsOfEvidenceDueDate\r\n",
					"            ,siteNoticesSentDate\r\n",
					"            ,statementDueDate\r\n",
					"            ,reasonForNeighbourVisits\r\n",
					"            ,numberOfResidencesNetChange\r\n",
					"            ,siteGridReferenceEasting\r\n",
					"            ,siteGridReferenceNorthing\r\n",
					"            ,siteViewableFromRoad\r\n",
					"            ,siteWithinSSSI\r\n",
					"            ,typeOfPlanningApplication\r\n",
					"            ,preserveGrantLoan\r\n",
					"            ,consultHistoricEngland        \r\n",
					"        FROM\r\n",
					"            odw_harmonised_db.sb_appeal_s78\r\n",
					"        WHERE\r\n",
					"            IsActive = 'Y'\r\n",
					"        \"\"\"\r\n",
					"        )\r\n",
					"        \r\n",
					"except Exception as e:\r\n",
					"    error_message = f\"Error in SQL query for table odw_harmonised_db.appeal-event : {str(e)[:800]}\"\r\n",
					"    end_exec_time = datetime.now() "
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Write the data to the curated table"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"try:\r\n",
					"    insert_count = df.count()\r\n",
					"    print(insert_count)\r\n",
					"    df.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(table_name)\r\n",
					"    print(f\"Written to {table_name}\")\r\n",
					"    \r\n",
					"    end_exec_time = datetime.now()\r\n",
					"   \r\n",
					"except Exception as e:\r\n",
					"    error_message = f\"Error appending data to the curated layer table : {str(e)[:800]}\"\r\n",
					"    end_exec_time = datetime.now()"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#####  Logging Execution Metadata to Azure Application Insights"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"try:\r\n",
					"    # Calculate execution duration\r\n",
					"    duration_seconds = (end_exec_time - start_exec_time).total_seconds()\r\n",
					"\r\n",
					"    # Define activity type\r\n",
					"    activity_type = f\"{mssparkutils.runtime.context['currentNotebookName']} Notebook\"\r\n",
					"\r\n",
					"    # Determine status and message\r\n",
					"    stage = \"Success\" if not error_message else \"Failed\"\r\n",
					"    status_message = (\r\n",
					"        f\"Successfully loaded data into {table_name} table\"\r\n",
					"        if not error_message\r\n",
					"        else f\"Failed to load data from {table_name} table\"\r\n",
					"    )\r\n",
					"    status_code = \"200\" if stage == \"Success\" else \"500\"\r\n",
					"\r\n",
					"    # Prepare telemetry parameters\r\n",
					"    params = {\r\n",
					"        \"Stage\": stage,\r\n",
					"        \"PipelineName\": PipelineName,\r\n",
					"        \"PipelineRunID\": PipelineRunID,\r\n",
					"        \"StartTime\": start_exec_time.isoformat(),\r\n",
					"        \"EndTime\": end_exec_time.isoformat(),\r\n",
					"        \"Inserts\": insert_count,\r\n",
					"        \"Updates\": update_count,\r\n",
					"        \"Deletes\": delete_count,\r\n",
					"        \"ErrorMessage\": error_message,\r\n",
					"        \"StatusMessage\": status_message,\r\n",
					"        \"PipelineTriggerID\": PipelineTriggerID,\r\n",
					"        \"PipelineTriggerName\": PipelineTriggerName,\r\n",
					"        \"PipelineTriggerType\": PipelineTriggerType,\r\n",
					"        \"PipelineTriggeredbyPipelineName\": PipelineTriggeredbyPipelineName,\r\n",
					"        \"PipelineTriggeredbyPipelineRunID\": PipelineTriggeredbyPipelineRunID,\r\n",
					"        \"PipelineExecutionTimeInSec\": duration_seconds,\r\n",
					"        \"ActivityType\": activity_type,\r\n",
					"        \"DurationSeconds\": duration_seconds,\r\n",
					"        \"StatusCode\": status_code,\r\n",
					"        \"AppInsCustomEventName\": \"ODW_Master_Pipeline_Logs\"\r\n",
					"    }\r\n",
					"\r\n",
					"    # Send telemetry asynchronously\r\n",
					"    send_telemetry_to_app_insights(params)\r\n",
					"\r\n",
					"    # Raise error if execution failed\r\n",
					"    if error_message:\r\n",
					"        print(f\"Notebook Failed for load {table_name} : {error_message}\")\r\n",
					"        raise RuntimeError(f\"Notebook Failed due to error in {table_name} Table: {error_message}\")\r\n",
					"\r\n",
					"except RuntimeError as e:\r\n",
					"    print(str(e))\r\n",
					"    import sys\r\n",
					"    sys.exit(1)"
				],
				"execution_count": null
			}
		]
	}
}