{
	"name": "lineage_test",
	"properties": {
		"folder": {
			"name": "odw-harmonised"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw34",
			"type": "BigDataPoolReference"
		},
		"targetSparkConfiguration": {
			"referenceName": "sparkConfiguration1",
			"type": "SparkConfigurationReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "752ded2b-1ba2-499b-acab-affe32327109"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw34",
				"name": "pinssynspodw34",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw34",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30,
			"targetSparkConfiguration": "sparkConfiguration1"
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"\"\"\"\n",
					"SAP HR Monthly Lineage Generator - CORRECTED\n",
					"Run this script to create lineage event for SAP HR transformation\n",
					"\"\"\"\n",
					"\n",
					"import json\n",
					"import datetime\n",
					"from notebookutils import mssparkutils\n",
					"\n",
					"print(\"=\"*80)\n",
					"print(\"SAP HR MONTHLY LINEAGE GENERATION\")\n",
					"print(\"=\"*80)\n",
					"\n",
					"# ============================================================================\n",
					"# STEP 1: Define Paths - CORRECTED CONTAINER NAME!\n",
					"# ============================================================================\n",
					"print(\"\\nStep 1: Defining file paths...\")\n",
					"\n",
					"STORAGE_ACCOUNT = \"pinsstodwdevuksl92q7c\"\n",
					"\n",
					"# CORRECTED: Container is \"odw-config\", not \"ls-storage\"\n",
					"SOURCE_SCHEMA_PATH = f\"abfss://odw-config@{STORAGE_ACCOUNT}.dfs.core.windows.net/standardised_table_definitions/saphr/sap_hr_history_monthly.json\"\n",
					"\n",
					"TARGET_SCHEMA_PATH = f\"abfss://odw-config@{STORAGE_ACCOUNT}.dfs.core.windows.net/harmonised_table_definitions/saphr/load_sap_hr_monthly.json\"\n",
					"\n",
					"# Events storage path\n",
					"EVENTS_PATH = f\"abfss://openlineage-events@{STORAGE_ACCOUNT}.dfs.core.windows.net\"\n",
					"\n",
					"# Namespace (your Synapse workspace)\n",
					"NAMESPACE = \"mssql://pins-synw-odw-dev-uks.sql.azuresynapse.net\"\n",
					"\n",
					"print(\"‚úÖ Paths defined\")\n",
					"print(f\"   Container: odw-config\")\n",
					"print(f\"   Source: standardised_table_definitions/saphr/sap_hr_history_monthly.json\")\n",
					"print(f\"   Target: harmonised_table_definitions/saphr/load_sap_hr_monthly.json\")\n",
					"\n",
					"# ============================================================================\n",
					"# STEP 2: Load Schema Files\n",
					"# ============================================================================\n",
					"print(\"\\nStep 2: Loading schema files...\")\n",
					"\n",
					"# Load source schema\n",
					"try:\n",
					"    source_content = mssparkutils.fs.head(SOURCE_SCHEMA_PATH, 100000)\n",
					"    source_schema = json.loads(source_content)\n",
					"    source_columns = len(source_schema.get('fields', []))\n",
					"    print(f\"‚úÖ Source schema loaded: {source_columns} columns\")\n",
					"except Exception as e:\n",
					"    print(f\"‚ùå ERROR loading source schema: {e}\")\n",
					"    print(f\"   Check file exists at: {SOURCE_SCHEMA_PATH}\")\n",
					"    source_schema = None\n",
					"    raise\n",
					"\n",
					"# Load target schema\n",
					"try:\n",
					"    target_content = mssparkutils.fs.head(TARGET_SCHEMA_PATH, 100000)\n",
					"    target_schema = json.loads(target_content)\n",
					"    target_columns = len(target_schema.get('fields', []))\n",
					"    print(f\"‚úÖ Target schema loaded: {target_columns} columns\")\n",
					"except Exception as e:\n",
					"    print(f\"‚ùå ERROR loading target schema: {e}\")\n",
					"    print(f\"   Check file exists at: {TARGET_SCHEMA_PATH}\")\n",
					"    target_schema = None\n",
					"    raise\n",
					"\n",
					"# ============================================================================\n",
					"# STEP 3: Build OpenLineage Event\n",
					"# ============================================================================\n",
					"print(\"\\nStep 3: Building OpenLineage event...\")\n",
					"\n",
					"# Generate unique run ID\n",
					"run_id = f\"load_sap_hr_monthly-{datetime.datetime.utcnow().strftime('%Y%m%d%H%M%S')}\"\n",
					"print(f\"   Run ID: {run_id}\")\n",
					"\n",
					"# Build INPUT dataset (source table)\n",
					"input_dataset = {\n",
					"    \"namespace\": NAMESPACE,\n",
					"    \"name\": \"odw_standardised_db.sap_hr_history_monthly\"\n",
					"}\n",
					"\n",
					"# Add source schema if available\n",
					"if source_schema:\n",
					"    input_dataset[\"facets\"] = {\n",
					"        \"schema\": {\n",
					"            \"fields\": [\n",
					"                {\n",
					"                    \"name\": field.get(\"name\"),\n",
					"                    \"type\": field.get(\"type\", \"string\")\n",
					"                }\n",
					"                for field in source_schema.get(\"fields\", [])\n",
					"            ]\n",
					"        }\n",
					"    }\n",
					"\n",
					"# Build OUTPUT dataset (target table)\n",
					"output_dataset = {\n",
					"    \"namespace\": NAMESPACE,\n",
					"    \"name\": \"odw_harmonised_db.load_sap_hr_monthly\"\n",
					"}\n",
					"\n",
					"# Add target schema if available\n",
					"if target_schema:\n",
					"    output_dataset[\"facets\"] = {\n",
					"        \"schema\": {\n",
					"            \"fields\": [\n",
					"                {\n",
					"                    \"name\": field.get(\"name\"),\n",
					"                    \"type\": field.get(\"type\", \"STRING\")\n",
					"                }\n",
					"                for field in target_schema.get(\"fields\", [])\n",
					"            ]\n",
					"        }\n",
					"    }\n",
					"\n",
					"# Create complete OpenLineage event\n",
					"event = {\n",
					"    \"eventType\": \"COMPLETE\",\n",
					"    \"eventTime\": datetime.datetime.utcnow().isoformat() + \"Z\",\n",
					"    \"producer\": \"sap-hr-lineage-generator\",\n",
					"    \"job\": {\n",
					"        \"namespace\": NAMESPACE,\n",
					"        \"name\": \"load_sap_hr_monthly\",\n",
					"        \"facets\": {\n",
					"            \"documentation\": {\n",
					"                \"description\": \"SAP HR monthly data transformation from standardised to harmonised layer\"\n",
					"            }\n",
					"        }\n",
					"    },\n",
					"    \"run\": {\n",
					"        \"runId\": run_id\n",
					"    },\n",
					"    \"inputs\": [input_dataset],\n",
					"    \"outputs\": [output_dataset]\n",
					"}\n",
					"\n",
					"print(\"‚úÖ Event structure created\")\n",
					"print(f\"   Input: odw_standardised_db.sap_hr_history_monthly\")\n",
					"print(f\"   Output: odw_harmonised_db.load_sap_hr_monthly\")\n",
					"\n",
					"# ============================================================================\n",
					"# STEP 4: Write Event to Storage\n",
					"# ============================================================================\n",
					"print(\"\\nStep 4: Writing event to blob storage...\")\n",
					"\n",
					"# Create dated folder path\n",
					"now = datetime.datetime.utcnow()\n",
					"year, month, day = now.strftime(\"%Y,%m,%d\").split(',')\n",
					"filename = f\"y={year}/m={month}/d={day}/{run_id}.json\"\n",
					"full_path = f\"{EVENTS_PATH}/{filename}\"\n",
					"\n",
					"print(f\"   Writing to: {filename}\")\n",
					"\n",
					"try:\n",
					"    # Write event as JSON\n",
					"    mssparkutils.fs.put(full_path, json.dumps(event, indent=2), True)\n",
					"    print(f\"‚úÖ Event written successfully!\")\n",
					"except Exception as e:\n",
					"    print(f\"‚ùå ERROR writing event: {e}\")\n",
					"    raise\n",
					"\n",
					"# ============================================================================\n",
					"# STEP 5: Verify Event Was Created\n",
					"# ============================================================================\n",
					"print(\"\\nStep 5: Verifying event file...\")\n",
					"\n",
					"try:\n",
					"    # List files in today's folder\n",
					"    folder_path = f\"{EVENTS_PATH}/y={year}/m={month}/d={day}/\"\n",
					"    files = mssparkutils.fs.ls(folder_path)\n",
					"    \n",
					"    # Find our event\n",
					"    our_event = [f for f in files if run_id in f.name]\n",
					"    \n",
					"    if our_event:\n",
					"        print(f\"‚úÖ Event file verified!\")\n",
					"        print(f\"   File name: {our_event[0].name}\")\n",
					"        print(f\"   File size: {our_event[0].size} bytes\")\n",
					"    else:\n",
					"        print(f\"‚ö†Ô∏è  Event file not found immediately (may need a moment)\")\n",
					"        \n",
					"except Exception as e:\n",
					"    print(f\"‚ö†Ô∏è  Could not verify (file may still exist): {e}\")\n",
					"\n",
					"# ============================================================================\n",
					"# SUMMARY\n",
					"# ============================================================================\n",
					"print(\"\\n\" + \"=\"*80)\n",
					"print(\"LINEAGE EVENT GENERATION COMPLETE!\")\n",
					"print(\"=\"*80)\n",
					"\n",
					"print(f\"\"\"\n",
					"‚úÖ What happened:\n",
					"   1. Loaded schemas from odw-config container\n",
					"   2. Created OpenLineage event with column-level metadata\n",
					"   3. Wrote event to: {filename}\n",
					"\n",
					"üìã Event Details:\n",
					"   ‚Ä¢ Source: odw_standardised_db.sap_hr_history_monthly ({source_columns} columns)\n",
					"   ‚Ä¢ Target: odw_harmonised_db.load_sap_hr_monthly ({target_columns} columns)\n",
					"   ‚Ä¢ Job Name: load_sap_hr_monthly\n",
					"   ‚Ä¢ Run ID: {run_id}\n",
					"\n",
					"üîÑ Next Steps:\n",
					"   1. Parser function will automatically pick up this event (5-10 minutes)\n",
					"   2. Parser will transform it to Purview format\n",
					"   3. Parser will upload to Purview\n",
					"   4. Lineage will appear in Purview!\n",
					"\n",
					"üîç Check Purview:\n",
					"   1. Go to: https://web.purview.azure.com\n",
					"   2. Search for: \"load_sap_hr_monthly\"\n",
					"   3. Click on the table asset\n",
					"   4. Go to \"Lineage\" tab\n",
					"   5. You should see: sap_hr_history_monthly ‚Üí load_sap_hr_monthly\n",
					"\n",
					"‚è±Ô∏è  Wait 5-10 minutes for parser to process this event\n",
					"\"\"\")\n",
					"\n",
					"print(\"=\"*80)"
				],
				"execution_count": 3
			}
		]
	}
}